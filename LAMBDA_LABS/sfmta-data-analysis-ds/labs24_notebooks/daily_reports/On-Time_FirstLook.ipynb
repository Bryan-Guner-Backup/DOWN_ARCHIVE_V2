{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from time import time, mktime\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "from math import cos, sqrt\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_id = '1'\n",
    "date = '2020-05-26'\n",
    "\n",
    "stops_url = 'https://raw.githubusercontent.com/Lambda-School-Labs/sfmta-data-analysis-ds/master/deprecated_assets/datasets/route_info.csv'\n",
    "schedules_url = 'http://sfmta-ds.eba-hqpuyrup.us-east-1.elasticbeanstalk.com/get-route-info' # needs to be updated with api url when live\n",
    "daily_url = 'http://sfmta-ds.eba-hqpuyrup.us-east-1.elasticbeanstalk.com/daily-general-json'\n",
    "\n",
    "stops = pd.read_csv(stops_url)\n",
    "sched_json = requests.get(schedules_url, params={'route_id': route_id,\n",
    "                                                 'day': date}).json()\n",
    "daily_json = requests.get(daily_url, params={'day': date}).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Look At Calculating On-Time %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcc_projection(loc1, loc2):\n",
    "    \"\"\"\n",
    "    function to apply FCC recommended formulae\n",
    "    for calculating distances on earth projected to a plane\n",
    "    \n",
    "    significantly faster computationally, negligible loss in accuracy\n",
    "    \n",
    "    Args: \n",
    "    loc1 - a tuple of lat/lon\n",
    "    loc2 - a tuple of lat/lon\n",
    "    \"\"\"\n",
    "    lat1, lat2 = loc1[0], loc2[0]\n",
    "    lon1, lon2 = loc1[1], loc2[1]\n",
    "    \n",
    "    mean_lat = (lat1+lat2)/2\n",
    "    delta_lat = lat2 - lat1\n",
    "    delta_lon = lon2 - lon1\n",
    "    \n",
    "    k1 = 111.13209 - 0.56605*cos(2*mean_lat) + .0012*cos(4*mean_lat)\n",
    "    k2 = 111.41513*cos(mean_lat) - 0.09455*cos(3*mean_lat) + 0.00012*cos(5*mean_lat)\n",
    "    \n",
    "    distance = sqrt((k1*delta_lat)**2 + (k2*delta_lon)**2)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_stops(df, stops):\n",
    "    \"\"\"\n",
    "    applies basic wrangling function\n",
    "    calculates nearest stop from reported location in km\n",
    "    returns dataframe with reported location, \n",
    "    nearest stop (coords and name), and distance between\n",
    "\n",
    "    tested with single buses on single routes on a single day;\n",
    "    technically route/vehicle/time agnostic\n",
    "    don't foresee any issues generalizing\n",
    "    \n",
    "    implements FCC projection formulae for calculating distance\n",
    "    \n",
    "    Args:\n",
    "    df - dataframe of transit data, requires 'latitude', 'longitude' columns\n",
    "    stops - datafram of stops data, requires 'lat', 'lon', 'title' columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # TO-DO: error handling for missing routes from either df or stops\n",
    "    # Currently handling by intersecting sets during function call\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    # creating list of lat/lon dictionaries for stops and reported bus locations\n",
    "    stop_lats = stops['lat'].values\n",
    "    stop_lons = stops['lon'].values\n",
    "\n",
    "    reported_lats = df['latitude'].values\n",
    "    reported_lons = df['longitude'].values\n",
    "\n",
    "    stop_points = [{'latitude': stop_lats[x], 'longitude': stop_lons[x]} \n",
    "                 for x in range(len(stops))]\n",
    "\n",
    "    reported_points = [{'latitude': reported_lats[x], \n",
    "                      'longitude': reported_lons[x]} \n",
    "                     for x in range(len(df))]\n",
    "\n",
    "    # to minimize possible overlap between probable stops\n",
    "    # 500 ft as km\n",
    "    # upper end of previous range for minimum distance between stops according to sfmta\n",
    "    # this value seems good but could use more testing\n",
    "    radius = .1524\n",
    "\n",
    "    # dict to tuples to play nice with geopy\n",
    "    stop_point_tuples = [tuple(stop_points[x].values()) \n",
    "                       for x in range(len(stop_points))]\n",
    "\n",
    "    reported_point_tuples = [tuple(reported_points[x].values()) \n",
    "                           for x in range(len(reported_points))]\n",
    "\n",
    "    df['reported_location'] = reported_point_tuples\n",
    "    \n",
    "    print('Prep Complete')\n",
    "    \n",
    "    # generating ((lat/lon), distance) tuples for nearest stop within range\n",
    "    # using FCC ellipsoidal earth projection\n",
    "    distances = [{x: fcc_projection(location, x) \n",
    "                 for x in stop_point_tuples} \n",
    "                 for location in reported_point_tuples]\n",
    "    \n",
    "    print(f'Distances Generated => {len(distances)}')\n",
    "    \n",
    "    # sorting for nearest stop\n",
    "    distances_sorted = [{k: v for k, v in sorted(distances[x].items(), \n",
    "                                                 key=itemgetter(1))}\n",
    "                       for x in range(len(distances))]\n",
    "    \n",
    "    print(f'Distances Sorted => {len(distances_sorted)}')\n",
    "    \n",
    "    # creating list of nearest stops\n",
    "    # nearest stop if nearest stop within radius, else None\n",
    "    point_stops = [next(iter(distances_sorted[x].items())) \n",
    "                   if next(iter(distances_sorted[x].items()))[1] <= radius \n",
    "                   else None\n",
    "                   for x in range(len(distances_sorted))]\n",
    "    \n",
    "    print(f'Stops Created => {len(point_stops)}')\n",
    "    \n",
    "    # assigning stop name from stops table based on lat/lon from previous step\n",
    "    stop_tuples = list(zip(stops.lat, stops.lon))\n",
    "    stop_titles = [stops.title.iloc[stop_tuples.index(stop[0])] \n",
    "                   if stop != None\n",
    "                   else None \n",
    "                   for stop in point_stops]\n",
    "    \n",
    "    print(f'Titles Created => {len(stop_titles)}')\n",
    "    \n",
    "    # pulling lat/lon and distance from tuples for df\n",
    "    df['nearest_stop'] = [x[0] if x != None else None for x in point_stops]\n",
    "    df['distance_in_km'] = [x[1] if x != None else None for x in point_stops]\n",
    "\n",
    "    # pulling stop names from list for df\n",
    "    df['title'] = stop_titles\n",
    "\n",
    "    # dropping columns of redundant information\n",
    "    df = df.drop(columns=['age', 'rid', 'latitude', 'longitude', 'timestamp',\n",
    "                          'kph', 'heading'])\n",
    "    end = time()\n",
    "    \n",
    "    print(f'DF Complete\\nTime Elapsed: {end-start} seconds\\n')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_timestamp(df):\n",
    "    times = df.timestamp.values\n",
    "    ages = df.age.values\n",
    "\n",
    "    df['adjusted_timestamp'] = [pd.Timestamp(times[x]) - \n",
    "                                pd.Timedelta(seconds=ages[x]) \n",
    "                                for x in range(len(df.timestamp))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function To Calculate On-Time %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_on_time(stops, daily_json, schedules_json):\n",
    "    \n",
    "    route = schedules_json['route']\n",
    "    intervals = schedules_json['intervals']\n",
    "    stop_list = schedules_json['stops']\n",
    "    inbound, outbound = pd.read_json(sched_json['inbound']), pd.read_json(sched_json['outbound'])\n",
    "    \n",
    "    locations = pd.DataFrame(data=daily_json).dropna()\n",
    "    locations = locations[locations.rid.eq(route)]\n",
    "    \n",
    "    locations['direction'] = ['Inbound' if '1____I' in x \n",
    "                              else 'Outbound' if '1____O' in x\n",
    "                              else None\n",
    "                              for x in locations.direction.values]\n",
    "    \n",
    "    stops = stops[stops.route_id.eq(route)]\n",
    "    stops = stops[stops.tag.isin(stop_list)]\n",
    "    stops = stops.rename(columns={'dir': 'direction'})\n",
    "    \n",
    "    locations = adjust_timestamp(locations)\n",
    "    \n",
    "    locations['unix_timestamp'] = locations['adjusted_timestamp'].apply(lambda d: \n",
    "                                                                        mktime(d.timetuple()))\n",
    "    \n",
    "    locations = assign_stops(locations, stops)\n",
    "    \n",
    "    locations = locations.merge(stops[stops.route_id.eq(route)], how='left', on=['direction', 'title'])\n",
    "    locations = locations.drop(columns=['route_id', 'lat', 'lon', 'stopId']).dropna()\n",
    "    \n",
    "    scheduled_times = []\n",
    "    serviced_times = []\n",
    "    for x in inbound:\n",
    "        if x in locations.tag.values:\n",
    "            \n",
    "            stop_times = pd.to_datetime(inbound[x].dropna())\n",
    "            bus_times = locations[locations.direction.eq('Inbound')\n",
    "                                  & locations.tag.eq(x)\n",
    "                                  & locations.adjusted_timestamp.dt.time.between(\n",
    "                                      min(stop_times.dt.time), \n",
    "                                      max(stop_times.dt.time))\n",
    "                                 ][['adjusted_timestamp', 'unix_timestamp', 'reported_location',\n",
    "                                    'distance_in_km', 'vid', 'tag']]\n",
    "            \n",
    "            scheduled_times.append(stop_times.reset_index(drop=True).dt.time)\n",
    "            serviced_times.append(bus_times.reset_index(drop=True))\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "            \n",
    "    return scheduled_times, serviced_times, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_from_timestamp(timestamp, bins):\n",
    "    diffs = [abs(timestamp - x) for x in bins]\n",
    "    return bins[diffs.index(min(diffs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep Complete\n",
      "Distances Generated => 11399\n",
      "Distances Sorted => 11399\n",
      "Stops Created => 11399\n",
      "Titles Created => 11399\n",
      "DF Complete\n",
      "Time Elapsed: 0.974747896194458 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scheduled_times, serviced_times, locations = find_on_time(stops, daily_json, sched_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Shoot, I don't know. \n",
    "\n",
    "Been trying to figure out an approach for this all day; best I've done is filter bus locations so we're only worried about busses that reported:\n",
    "- while active on a route\n",
    "- at or near a stop\n",
    "- that exists in the selected route\n",
    "- and exists in the current schedule for that route\n",
    "- where the busses Inbound/Outbound indicator matched the scheduled stop's Inbound/Outbound status\n",
    "- and the timestamp of the report is within the scheduled service time\n",
    "\n",
    "So theoretically I've eliminated all (or most) of the data that won't actually be useful in strictly determining whether or not a stop is being serviced on-time. I just have no clue how to get from here to there.\n",
    "\n",
    "Currently the funcion spits out:\n",
    "- a list of datetime series of scheduled stop times by stop\n",
    "- a list of datarames filtered as above, also filtered by stop\n",
    "- the full dataframe for the specified date, filtered as above\n",
    "\n",
    "Intuitively it feels like there must be some simple next step, given the data, to completion. But idk ¯\\\\_(ツ)_/¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2020-06-02 05:00:00\n",
       "1     2020-06-02 05:08:00\n",
       "2     2020-06-02 05:16:00\n",
       "3     2020-06-02 05:24:00\n",
       "4     2020-06-02 05:32:00\n",
       "              ...        \n",
       "137   2020-06-02 22:16:00\n",
       "138   2020-06-02 22:24:00\n",
       "139   2020-06-02 22:32:00\n",
       "140   2020-06-02 22:40:00\n",
       "141   2020-06-02 22:48:00\n",
       "Name: 4277, Length: 142, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timedelta('0 days 00:01:33'),\n",
       " Timedelta('0 days 00:00:13'),\n",
       " Timedelta('0 days 00:00:50'),\n",
       " Timedelta('0 days 00:01:57'),\n",
       " Timedelta('0 days 00:00:12'),\n",
       " Timedelta('0 days 01:30:40'),\n",
       " Timedelta('0 days 05:07:45'),\n",
       " Timedelta('0 days 00:00:51'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:01:15'),\n",
       " Timedelta('0 days 00:02:48'),\n",
       " Timedelta('0 days 00:00:54'),\n",
       " Timedelta('0 days 00:01:04'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:00:55'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:03:39'),\n",
       " Timedelta('0 days 00:01:45'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:00:50'),\n",
       " Timedelta('0 days 00:01:08'),\n",
       " Timedelta('0 days 00:01:54'),\n",
       " Timedelta('0 days 00:00:53'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:01:04'),\n",
       " Timedelta('0 days 00:00:12'),\n",
       " Timedelta('0 days 00:00:50'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:53'),\n",
       " Timedelta('0 days 00:00:12'),\n",
       " Timedelta('0 days 00:00:25'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:00:49'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:01:16'),\n",
       " Timedelta('-1 days +23:59:48'),\n",
       " Timedelta('0 days 00:01:16'),\n",
       " Timedelta('-1 days +23:59:47'),\n",
       " Timedelta('0 days 00:01:16'),\n",
       " Timedelta('-1 days +23:59:34'),\n",
       " Timedelta('0 days 00:01:28'),\n",
       " Timedelta('0 days 00:00:49'),\n",
       " Timedelta('0 days 00:01:04'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:00:49'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:51'),\n",
       " Timedelta('0 days 00:00:13'),\n",
       " Timedelta('0 days 00:00:49'),\n",
       " Timedelta('0 days 00:00:12'),\n",
       " Timedelta('0 days 00:01:16'),\n",
       " Timedelta('-1 days +23:59:48'),\n",
       " Timedelta('0 days 00:02:17'),\n",
       " Timedelta('0 days 00:00:24'),\n",
       " Timedelta('0 days 00:01:04'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:00:49'),\n",
       " Timedelta('0 days 00:03:11'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:01:04'),\n",
       " Timedelta('0 days 00:00:50'),\n",
       " Timedelta('0 days 00:01:07'),\n",
       " Timedelta('0 days 00:00:51'),\n",
       " Timedelta('0 days 06:49:34'),\n",
       " Timedelta('0 days 00:06:24'),\n",
       " Timedelta('0 days 00:14:33'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:02:41'),\n",
       " Timedelta('0 days 00:02:16'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:00:13'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:14:08'),\n",
       " Timedelta('0 days 00:00:48'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:01:03'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:01:02'),\n",
       " Timedelta('0 days 00:00:50'),\n",
       " Timedelta('0 days 00:01:04'),\n",
       " Timedelta('0 days 00:01:18'),\n",
       " Timedelta('-1 days +23:59:48'),\n",
       " Timedelta('0 days 00:01:15'),\n",
       " Timedelta('-1 days +23:59:35'),\n",
       " Timedelta('0 days 00:01:28'),\n",
       " Timedelta('-1 days +23:59:35'),\n",
       " Timedelta('0 days 00:01:15'),\n",
       " Timedelta('-1 days +23:59:47'),\n",
       " Timedelta('0 days 00:01:18'),\n",
       " Timedelta('-1 days +23:59:48'),\n",
       " Timedelta('0 days 00:01:15'),\n",
       " Timedelta('-1 days +23:59:35'),\n",
       " Timedelta('0 days 00:01:27'),\n",
       " Timedelta('-1 days +23:59:36'),\n",
       " Timedelta('0 days 00:01:14'),\n",
       " Timedelta('-1 days +23:59:47'),\n",
       " Timedelta('0 days 00:01:14'),\n",
       " Timedelta('-1 days +23:59:48'),\n",
       " Timedelta('0 days 00:01:14'),\n",
       " Timedelta('-1 days +23:59:48'),\n",
       " Timedelta('0 days 00:01:17'),\n",
       " Timedelta('-1 days +23:59:48'),\n",
       " Timedelta('0 days 00:01:14'),\n",
       " Timedelta('-1 days +23:59:35')]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pd.Timestamp(times2[0].loc[x+1, 'adjusted_timestamp'])\n",
    " - pd.Timestamp(times2[0].loc[x,  'adjusted_timestamp']) \n",
    " for x in range(0, len(times2[0])-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2020-06-02 05:00:00\n",
       "1     2020-06-02 05:08:00\n",
       "2     2020-06-02 05:16:00\n",
       "3     2020-06-02 05:24:00\n",
       "4     2020-06-02 05:32:00\n",
       "              ...        \n",
       "137   2020-06-02 22:16:00\n",
       "138   2020-06-02 22:24:00\n",
       "139   2020-06-02 22:32:00\n",
       "140   2020-06-02 22:40:00\n",
       "141   2020-06-02 22:48:00\n",
       "Name: 4277, Length: 142, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.DataFrame(times1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.591096e+09\n",
       "1      1.591096e+09\n",
       "2      1.591097e+09\n",
       "3      1.591097e+09\n",
       "4      1.591098e+09\n",
       "           ...     \n",
       "137    1.591158e+09\n",
       "138    1.591158e+09\n",
       "139    1.591159e+09\n",
       "140    1.591159e+09\n",
       "141    1.591160e+09\n",
       "Name: 4277, Length: 142, dtype: float64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf[4277].apply(lambda d:\n",
    "                    mktime(pd.Timestamp(d).timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = datetime.timedelta(minutes=8)\n",
    "\n",
    "time_bins = [np.arange(np.min(times2[x]['unix_timestamp']),\n",
    "                     np.max(times2[x]['unix_timestamp'])\n",
    "                     + delta.seconds, delta.seconds) \n",
    "                     for x in range(len(times2))]\n",
    "\n",
    "binned_dfs = [times2[x].groupby(times2[x].unix_timestamp\n",
    "                           .map(lambda t: \n",
    "                                datetime.datetime.fromtimestamp(\n",
    "                                    bin_from_timestamp(t, time_bins[x]))))\n",
    "                  for x in range(len(time_bins))]\n",
    "\n",
    "binned_locs = [{str(x): df.get_group(str(x))\n",
    "                    for x, y in df} for df in binned_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjusted_timestamp</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>reported_location</th>\n",
       "      <th>distance_in_km</th>\n",
       "      <th>vid</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-26 06:02:37</td>\n",
       "      <td>1.590495e+09</td>\n",
       "      <td>(37.7798, -122.493)</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>5831</td>\n",
       "      <td>4277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-26 06:04:10</td>\n",
       "      <td>1.590495e+09</td>\n",
       "      <td>(37.7798, -122.493)</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>5831</td>\n",
       "      <td>4277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-26 06:04:23</td>\n",
       "      <td>1.590495e+09</td>\n",
       "      <td>(37.7798, -122.493)</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>5831</td>\n",
       "      <td>4277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-26 06:05:13</td>\n",
       "      <td>1.590495e+09</td>\n",
       "      <td>(37.7798, -122.493)</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>5831</td>\n",
       "      <td>4277.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adjusted_timestamp  unix_timestamp    reported_location  distance_in_km  \\\n",
       "0 2020-05-26 06:02:37    1.590495e+09  (37.7798, -122.493)        0.013898   \n",
       "1 2020-05-26 06:04:10    1.590495e+09  (37.7798, -122.493)        0.013898   \n",
       "2 2020-05-26 06:04:23    1.590495e+09  (37.7798, -122.493)        0.013898   \n",
       "3 2020-05-26 06:05:13    1.590495e+09  (37.7798, -122.493)        0.013898   \n",
       "\n",
       "    vid     tag  \n",
       "0  5831  4277.0  \n",
       "1  5831  4277.0  \n",
       "2  5831  4277.0  \n",
       "3  5831  4277.0  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned_locs[0]['2020-05-26 06:02:37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:08:00')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp(inbound[4277][157])-pd.Timestamp(inbound[4277][156])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid</th>\n",
       "      <th>direction</th>\n",
       "      <th>adjusted_timestamp</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>reported_location</th>\n",
       "      <th>nearest_stop</th>\n",
       "      <th>distance_in_km</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5770</td>\n",
       "      <td>Inbound</td>\n",
       "      <td>2020-05-26 03:49:03</td>\n",
       "      <td>1.590487e+09</td>\n",
       "      <td>(37.7924, -122.421)</td>\n",
       "      <td>(37.7923599, -122.42101000000001)</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>Clay St &amp; Polk St</td>\n",
       "      <td>4026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5770</td>\n",
       "      <td>Inbound</td>\n",
       "      <td>2020-05-26 03:52:07</td>\n",
       "      <td>1.590487e+09</td>\n",
       "      <td>(37.7939, -122.409)</td>\n",
       "      <td>(37.7938299, -122.40959)</td>\n",
       "      <td>0.065844</td>\n",
       "      <td>Clay St &amp; Powell St</td>\n",
       "      <td>4027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5873</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>2020-05-26 03:52:07</td>\n",
       "      <td>1.590487e+09</td>\n",
       "      <td>(37.7799, -122.492)</td>\n",
       "      <td>(37.779739899999996, -122.49311000000002)</td>\n",
       "      <td>0.124432</td>\n",
       "      <td>Geary Blvd &amp; 33rd Ave</td>\n",
       "      <td>34277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5873</td>\n",
       "      <td>Inbound</td>\n",
       "      <td>2020-05-26 03:53:09</td>\n",
       "      <td>1.590487e+09</td>\n",
       "      <td>(37.7798, -122.493)</td>\n",
       "      <td>(37.779739899999996, -122.49311000000002)</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>Geary Blvd &amp; 33rd Ave</td>\n",
       "      <td>4277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5873</td>\n",
       "      <td>Inbound</td>\n",
       "      <td>2020-05-26 03:54:09</td>\n",
       "      <td>1.590487e+09</td>\n",
       "      <td>(37.7798, -122.493)</td>\n",
       "      <td>(37.779739899999996, -122.49311000000002)</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>Geary Blvd &amp; 33rd Ave</td>\n",
       "      <td>4277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>5877</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>2020-05-26 21:49:25</td>\n",
       "      <td>1.590551e+09</td>\n",
       "      <td>(37.7932, -122.408)</td>\n",
       "      <td>(37.7930399, -122.40912)</td>\n",
       "      <td>0.125388</td>\n",
       "      <td>Sacramento St &amp; Powell St</td>\n",
       "      <td>6312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>5877</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>2020-05-26 21:53:33</td>\n",
       "      <td>1.590552e+09</td>\n",
       "      <td>(37.7917, -122.42)</td>\n",
       "      <td>(37.7915199, -122.42115)</td>\n",
       "      <td>0.129021</td>\n",
       "      <td>Sacramento St &amp; Polk St</td>\n",
       "      <td>6311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11390</th>\n",
       "      <td>5877</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>2020-05-26 21:54:23</td>\n",
       "      <td>1.590552e+09</td>\n",
       "      <td>(37.7914, -122.422)</td>\n",
       "      <td>(37.7915199, -122.42115)</td>\n",
       "      <td>0.095150</td>\n",
       "      <td>Sacramento St &amp; Polk St</td>\n",
       "      <td>6311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11395</th>\n",
       "      <td>5877</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>2020-05-26 21:59:36</td>\n",
       "      <td>1.590552e+09</td>\n",
       "      <td>(37.7899, -122.434)</td>\n",
       "      <td>(37.7898199, -122.43399)</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>Sacramento St &amp; Fillmore St</td>\n",
       "      <td>6295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11398</th>\n",
       "      <td>5877</td>\n",
       "      <td>Outbound</td>\n",
       "      <td>2020-05-26 22:03:05</td>\n",
       "      <td>1.590552e+09</td>\n",
       "      <td>(37.7875, -122.446)</td>\n",
       "      <td>(37.7872099, -122.44693000000001)</td>\n",
       "      <td>0.108002</td>\n",
       "      <td>California St &amp; Presidio Ave</td>\n",
       "      <td>3892.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3384 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        vid direction  adjusted_timestamp  unix_timestamp  \\\n",
       "6      5770   Inbound 2020-05-26 03:49:03    1.590487e+09   \n",
       "12     5770   Inbound 2020-05-26 03:52:07    1.590487e+09   \n",
       "13     5873  Outbound 2020-05-26 03:52:07    1.590487e+09   \n",
       "14     5873   Inbound 2020-05-26 03:53:09    1.590487e+09   \n",
       "17     5873   Inbound 2020-05-26 03:54:09    1.590487e+09   \n",
       "...     ...       ...                 ...             ...   \n",
       "11384  5877  Outbound 2020-05-26 21:49:25    1.590551e+09   \n",
       "11389  5877  Outbound 2020-05-26 21:53:33    1.590552e+09   \n",
       "11390  5877  Outbound 2020-05-26 21:54:23    1.590552e+09   \n",
       "11395  5877  Outbound 2020-05-26 21:59:36    1.590552e+09   \n",
       "11398  5877  Outbound 2020-05-26 22:03:05    1.590552e+09   \n",
       "\n",
       "         reported_location                               nearest_stop  \\\n",
       "6      (37.7924, -122.421)          (37.7923599, -122.42101000000001)   \n",
       "12     (37.7939, -122.409)                   (37.7938299, -122.40959)   \n",
       "13     (37.7799, -122.492)  (37.779739899999996, -122.49311000000002)   \n",
       "14     (37.7798, -122.493)  (37.779739899999996, -122.49311000000002)   \n",
       "17     (37.7798, -122.493)  (37.779739899999996, -122.49311000000002)   \n",
       "...                    ...                                        ...   \n",
       "11384  (37.7932, -122.408)                   (37.7930399, -122.40912)   \n",
       "11389   (37.7917, -122.42)                   (37.7915199, -122.42115)   \n",
       "11390  (37.7914, -122.422)                   (37.7915199, -122.42115)   \n",
       "11395  (37.7899, -122.434)                   (37.7898199, -122.43399)   \n",
       "11398  (37.7875, -122.446)          (37.7872099, -122.44693000000001)   \n",
       "\n",
       "       distance_in_km                         title      tag  \n",
       "6            0.004571             Clay St & Polk St   4026.0  \n",
       "12           0.065844           Clay St & Powell St   4027.0  \n",
       "13           0.124432         Geary Blvd & 33rd Ave  34277.0  \n",
       "14           0.013898         Geary Blvd & 33rd Ave   4277.0  \n",
       "17           0.013898         Geary Blvd & 33rd Ave   4277.0  \n",
       "...               ...                           ...      ...  \n",
       "11384        0.125388     Sacramento St & Powell St   6312.0  \n",
       "11389        0.129021       Sacramento St & Polk St   6311.0  \n",
       "11390        0.095150       Sacramento St & Polk St   6311.0  \n",
       "11395        0.008926   Sacramento St & Fillmore St   6295.0  \n",
       "11398        0.108002  California St & Presidio Ave   3892.0  \n",
       "\n",
       "[3384 rows x 9 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
