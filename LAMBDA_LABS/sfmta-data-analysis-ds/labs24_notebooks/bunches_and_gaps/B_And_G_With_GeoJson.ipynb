{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B_And_G_With_GeoJson.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z774PSkAveGP",
        "colab_type": "text"
      },
      "source": [
        "## Run Once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfNvb0CAuQ3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used in many places\n",
        "import psycopg2 as pg\n",
        "import pandas as pd\n",
        "\n",
        "# Used to enter database credentials without saving them to the notebook file\n",
        "import getpass\n",
        "\n",
        "# Used to easily read in bus location data\n",
        "import pandas.io.sql as sqlio\n",
        "\n",
        "# Only used in the schedule class definition\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Used in the fcc_projection function to find distances\n",
        "from math import sqrt, cos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrXXS59_uSMB",
        "colab_type": "code",
        "outputId": "176df50d-bf55-4c92-f9d6-4a6fd7f71210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# Enter database credentials.  Requires you to paste in the user and\n",
        "# password so it isn't saved in the notebook file\n",
        "print(\"Enter database username:\")\n",
        "user = getpass.getpass()\n",
        "print(\"Enter database password:\")\n",
        "password = getpass.getpass()\n",
        "\n",
        "creds = {\n",
        "  'user': user,\n",
        "  'password': password,\n",
        "  'host': \"lambdalabs24sfmta.cykkiwxbfvpg.us-east-1.rds.amazonaws.com\",\n",
        "  'dbname': \"historicalTransitData\"\n",
        "}\n",
        "\n",
        "# Set up connection to database\n",
        "cnx = pg.connect(**creds)\n",
        "cursor = cnx.cursor()\n",
        "\n",
        "print('\\nDatabase connection successful')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter database username:\n",
            "··········\n",
            "Enter database password:\n",
            "··········\n",
            "\n",
            "Database connection successful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD5I_fodu1VO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Schedule class definition\n",
        "# Copied from previous work, has extra methods that are not all used in this notebook\n",
        "\n",
        "class Schedule:\n",
        "    def __init__(self, route_id, date, connection):\n",
        "        \"\"\"\n",
        "        The Schedule class loads the schedule for a particular route and day,\n",
        "        and makes several accessor methods available for it.\n",
        "\n",
        "        Parameters:\n",
        "\n",
        "        route_id (str or int)\n",
        "            - The route id to load\n",
        "\n",
        "        date (str or pandas.Timestamp)\n",
        "            - Which date to load\n",
        "            - Converted with pandas.to_datetime so many formats are acceptable\n",
        "        \"\"\"\n",
        "\n",
        "        self.route_id = str(route_id)\n",
        "        self.date = pd.to_datetime(date)\n",
        "\n",
        "        # load the schedule for that date and route\n",
        "        self.route_data = load_schedule(self.route_id, self.date, connection)\n",
        "\n",
        "        # process data into a table\n",
        "        self.inbound_table, self.outbound_table = extract_schedule_tables(self.route_data)\n",
        "\n",
        "        # calculate the common interval values\n",
        "        self.mean_interval, self.common_interval = get_common_intervals(\n",
        "                                    [self.inbound_table, self.outbound_table])\n",
        "\n",
        "    def list_stops(self):\n",
        "        \"\"\"\n",
        "        returns the list of all stops used by this schedule\n",
        "        \"\"\"\n",
        "\n",
        "        # get stops for both inbound and outbound routes\n",
        "        inbound = list(self.inbound_table.columns)\n",
        "        outbound = list(self.outbound_table.columns)\n",
        "\n",
        "        # convert to set to ensure no duplicates,\n",
        "        # then back to list for the correct output type\n",
        "        return list(set(inbound + outbound))\n",
        "\n",
        "    def get_specific_interval(self, stop, time, inbound=True):\n",
        "        \"\"\"\n",
        "        Returns the expected interval, in minutes, for a given stop and\n",
        "        time of day.\n",
        "\n",
        "        Parameters:\n",
        "\n",
        "        stop (str or int)\n",
        "            - the stop tag/id of the bus stop to check\n",
        "\n",
        "        time (str or pandas.Timestamp)\n",
        "            - the time of day to check, uses pandas.to_datetime to convert\n",
        "            - examples that work: \"6:00\", \"3:30pm\", \"15:30\"\n",
        "\n",
        "        inbound (bool, optional)\n",
        "            - whether to check the inbound or outbound schedule\n",
        "            - ignored unless the given stop is in both inbound and outbound\n",
        "        \"\"\"\n",
        "\n",
        "        # ensure correct parameter types\n",
        "        stop = str(stop)\n",
        "        time = pd.to_datetime(time)\n",
        "\n",
        "        # check which route to use, and extract the column for the given stop\n",
        "        if (stop in self.inbound_table.columns and\n",
        "        stop in self.outbound_table.columns):\n",
        "            # stop exists in both, use inbound parameter to decide\n",
        "            if inbound:\n",
        "                sched = self.inbound_table[stop]\n",
        "            else:\n",
        "                sched = self.outbound_table[stop]\n",
        "        elif (stop in self.inbound_table.columns):\n",
        "            # stop is in the inbound schedule, use that\n",
        "            sched = self.inbound_table[stop]\n",
        "        elif (stop in self.outbound_table.columns):\n",
        "            # stop is in the outbound schedule, use that\n",
        "            sched = self.outbound_table[stop]\n",
        "        else:\n",
        "            # stop doesn't exist in either, throw an error\n",
        "            raise ValueError(f\"Stop id '{stop}' doesn't exist in either inbound or outbound schedules\")\n",
        "\n",
        "        # 1: convert schedule to datetime for comparison statements\n",
        "        # 2: drop any NaN values\n",
        "        # 3: convert to list since pd.Series threw errors on i indexing\n",
        "        sched = list(pd.to_datetime(sched).dropna())\n",
        "\n",
        "        # reset the date portion of the time parameter to\n",
        "        # ensure we are checking the schedule correctly\n",
        "        time = time.replace(year=self.date.year, month=self.date.month,\n",
        "                            day=self.date.day)\n",
        "\n",
        "        # iterate through that list to find where the time parameter fits\n",
        "        for i in range(1, len(sched)):\n",
        "            # start at 1 and move forward,\n",
        "            # is the time parameter before this schedule entry?\n",
        "            if(time < sched[i]):\n",
        "                # return the difference between this entry and the previous one\n",
        "                return (sched[i] - sched[i-1]).seconds / 60\n",
        "\n",
        "        # can only reach this point if the time parameter is after all entries\n",
        "        # in the schedule, return the last available interval\n",
        "        return (sched[len(sched)-1] - sched[len(sched)-2]).seconds / 60\n",
        "\n",
        "\n",
        "def load_schedule(route, date, connection):\n",
        "    \"\"\"\n",
        "    loads schedule data from the database and returns it\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "        route (str)\n",
        "            - The route id to load\n",
        "\n",
        "        date (str or pd.Timestamp)\n",
        "            - Which date to load\n",
        "            - Converted with pandas.to_datetime so many formats are acceptable\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure correct parameter types\n",
        "    route = str(route)\n",
        "    date = pd.to_datetime(date)\n",
        "\n",
        "    # DB connection\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # build selection query\n",
        "    query = \"\"\"\n",
        "        SELECT content\n",
        "        FROM schedules\n",
        "        WHERE rid = %s AND\n",
        "            begin_date <= %s::TIMESTAMP AND\n",
        "            (end_date IS NULL OR end_date >= %s::TIMESTAMP);\n",
        "    \"\"\"\n",
        "\n",
        "    # execute query and save the route data to a local variable\n",
        "    cursor.execute(query, (route, str(date), str(date)))\n",
        "    data = cursor.fetchone()[0]['route']\n",
        "\n",
        "    # pd.Timestamp.dayofweek returns 0 for monday and 6 for Sunday\n",
        "    # the actual serviceClass strings are defined by Nextbus\n",
        "    # these are the only 3 service classes we can currently observe,\n",
        "    # if others are published later then this will need to change\n",
        "    if(date.dayofweek <= 4):\n",
        "        serviceClass = 'wkd'\n",
        "    elif(date.dayofweek == 5):\n",
        "        serviceClass = 'sat'\n",
        "    else:\n",
        "        serviceClass = 'sun'\n",
        "\n",
        "    # the schedule format has two entries for each serviceClass,\n",
        "    # one each for inbound and outbound.\n",
        "\n",
        "    # return each entry in the data list with the correct serviceClass\n",
        "    return [sched for sched in data if (sched['serviceClass'] == serviceClass)]\n",
        "\n",
        "\n",
        "def extract_schedule_tables(route_data):\n",
        "    \"\"\"\n",
        "    converts raw schedule data to two pandas dataframes\n",
        "\n",
        "    columns are stops, and rows are individual trips\n",
        "\n",
        "    returns inbound_df, outbound_df\n",
        "    \"\"\"\n",
        "\n",
        "    # assuming 2 entries, but not assuming order\n",
        "    if(route_data[0]['direction'] == 'Inbound'):\n",
        "        inbound = 0\n",
        "    else:\n",
        "        inbound = 1\n",
        "\n",
        "    # extract a list of stops to act as columns\n",
        "    inbound_stops = [s['tag'] for s in route_data[inbound]['header']['stop']]\n",
        "\n",
        "    # initialize dataframe\n",
        "    inbound_df = pd.DataFrame(columns=inbound_stops)\n",
        "\n",
        "    # extract each row from the data\n",
        "    if type(route_data[inbound]['tr']) == list:\n",
        "        # if there are multiple trips in a day, structure will be a list\n",
        "        i = 0\n",
        "        for trip in route_data[inbound]['tr']:\n",
        "            for stop in trip['stop']:\n",
        "                # '--' indicates the bus is not going to that stop on this trip\n",
        "                if stop['content'] != '--':\n",
        "                    inbound_df.at[i, stop['tag']] = stop['content']\n",
        "            # increment for the next row\n",
        "            i += 1\n",
        "    else:\n",
        "        # if there is only 1 trip in a day, the object is a dict and\n",
        "        # must be handled slightly differently\n",
        "        for stop in route_data[inbound]['tr']['stop']:\n",
        "            if stop['content'] != '--':\n",
        "                    inbound_df.at[0, stop['tag']] = stop['content']\n",
        "\n",
        "    # flip between 0 and 1\n",
        "    outbound = int(not inbound)\n",
        "\n",
        "    # repeat steps for the outbound schedule\n",
        "    outbound_stops = [s['tag'] for s in route_data[outbound]['header']['stop']]\n",
        "    outbound_df = pd.DataFrame(columns=outbound_stops)\n",
        "\n",
        "    if type(route_data[outbound]['tr']) == list:\n",
        "        i = 0\n",
        "        for trip in route_data[outbound]['tr']:\n",
        "            for stop in trip['stop']:\n",
        "                if stop['content'] != '--':\n",
        "                    outbound_df.at[i, stop['tag']] = stop['content']\n",
        "            i += 1\n",
        "    else:\n",
        "        for stop in route_data[outbound]['tr']['stop']:\n",
        "            if stop['content'] != '--':\n",
        "                    outbound_df.at[0, stop['tag']] = stop['content']\n",
        "\n",
        "    # return both dataframes\n",
        "    return inbound_df, outbound_df\n",
        "\n",
        "\n",
        "def get_common_intervals(df_list):\n",
        "    \"\"\"\n",
        "    takes route schedule tables and returns both the average interval (mean)\n",
        "    and the most common interval (mode), measured in number of minutes\n",
        "\n",
        "    takes a list of dataframes and combines them before calculating statistics\n",
        "\n",
        "    intended to combine inbound and outbound schedules for a single route\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure we have at least one dataframe\n",
        "    if len(df_list) == 0:\n",
        "        raise ValueError(\"Function requires at least one dataframe\")\n",
        "\n",
        "    # append all dataframes in the array together\n",
        "    df = df_list[0].copy()\n",
        "    for i in range(1, len(df_list)):\n",
        "        df.append(df_list[i].copy())\n",
        "\n",
        "    # convert all values to datetime so we can get an interval easily\n",
        "    for col in df.columns:\n",
        "        df[col] = pd.to_datetime(df[col])\n",
        "\n",
        "    # initialize a table to hold each individual interval\n",
        "    intervals = pd.DataFrame(columns=df.columns)\n",
        "    intervals['temp'] = range(len(df))\n",
        "\n",
        "    # take each column and find the intervals in it\n",
        "    for col in df.columns:\n",
        "        prev_time = np.nan\n",
        "        for i in range(len(df)):\n",
        "            # find the first non-null value and save it to prev_time\n",
        "            if pd.isnull(prev_time):\n",
        "                prev_time = df.at[i, col]\n",
        "            # if the current time is not null, save the interval\n",
        "            elif ~pd.isnull(df.at[i, col]):\n",
        "                intervals.at[i, col] = (df.at[i, col] - prev_time).seconds / 60\n",
        "                prev_time = df.at[i, col]\n",
        "\n",
        "    # this runs without adding a temp column, but the above loop runs 3x as\n",
        "    # fast if the rows already exist\n",
        "    intervals = intervals.drop('temp', axis=1)\n",
        "\n",
        "    # calculate the mean of the entire table\n",
        "    mean = intervals.mean().mean()\n",
        "\n",
        "    # calculate the mode of the entire table, the [0][0] at the end is\n",
        "    # because scipy.stats returns an entire ModeResult class\n",
        "    mode = stats.mode(intervals.values.flatten())[0][0]\n",
        "\n",
        "    return mean, mode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJzK7mePwLD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Route class definition\n",
        "# Copied from previous work, has extra methods that are not all used in this notebook\n",
        "\n",
        "class Route:\n",
        "    def __init__(self, route_id, date, connection):\n",
        "        \"\"\"\n",
        "        The Route class loads the route configuration data for a particular\n",
        "        route, and makes several accessor methods available for it.\n",
        "\n",
        "        Parameters:\n",
        "\n",
        "        route_id (str or int)\n",
        "            - The route id to load\n",
        "\n",
        "        date (str or pandas.Timestamp)\n",
        "            - Which date to load\n",
        "            - Converted with pandas.to_datetime so many formats are acceptable\n",
        "        \"\"\"\n",
        "\n",
        "        self.route_id = str(route_id)\n",
        "        self.date = pd.to_datetime(date)\n",
        "\n",
        "        # load the route data\n",
        "        self.route_data, self.route_type, self.route_name = load_route(self.route_id, self.date, connection)\n",
        "\n",
        "        # extract stops info and rearrange columns to be more human readable\n",
        "        # note: the stop tag is what was used in the schedule data, not stopId\n",
        "        self.stops_table = pd.DataFrame(self.route_data['stop'])\n",
        "        self.stops_table = self.stops_table[['stopId', 'tag', 'title', 'lat', 'lon']]\n",
        "\n",
        "        # extract route path, list of (lat, lon) pairs\n",
        "        self.path_coords = extract_path(self.route_data)\n",
        "\n",
        "        # extract stops table\n",
        "        self.stops_table, self.inbound, self.outbound = extract_stops(self.route_data)\n",
        "\n",
        "\n",
        "def load_route(route, date, connection):\n",
        "    \"\"\"\n",
        "    loads raw route data from the database\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "        route (str or int)\n",
        "            - The route id to load\n",
        "\n",
        "        date (str or pd.Timestamp)\n",
        "            - Which date to load\n",
        "            - Converted with pandas.to_datetime so many formats are acceptable\n",
        "    \n",
        "    Returns route_data (dict), route_type (str), route_name (str)\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure correct parameter types\n",
        "    route = str(route)\n",
        "    date = pd.to_datetime(date)\n",
        "\n",
        "    # DB connection\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # build selection query\n",
        "    query = \"\"\"\n",
        "        SELECT route_name, route_type, content\n",
        "        FROM routes\n",
        "        WHERE rid = %s AND\n",
        "            begin_date <= %s::TIMESTAMP AND\n",
        "            (end_date IS NULL OR end_date > %s::TIMESTAMP);\n",
        "    \"\"\"\n",
        "\n",
        "    # execute query and return the route data\n",
        "    cursor.execute(query, (route, str(date), str(date)))\n",
        "    result = cursor.fetchone()\n",
        "    return result[2]['route'], result[1], result[0]\n",
        "\n",
        "\n",
        "def extract_path(route_data):\n",
        "    \"\"\"\n",
        "    Extracts the list of path coordinates for a route.\n",
        "\n",
        "    The raw data stores this as an unordered list of sub-routes, so this\n",
        "    function deciphers the order they should go in and returns a single list.\n",
        "    \"\"\"\n",
        "\n",
        "    # KNOWN BUG\n",
        "    # this approach assumed all routes were either a line or a loop.\n",
        "    # routes that have multiple sub-paths meeting at a point break this,\n",
        "    # route 24 is a current example.\n",
        "    # I'm committing this now to get the rest of the code out there\n",
        "\n",
        "    # extract the list of subpaths as just (lat,lon) coordinates\n",
        "    # also converts from string to float (raw data has strings)\n",
        "    path = []\n",
        "    for sub_path in route_data['path']:\n",
        "        path.append([(float(p['lat']), float(p['lon'])) \n",
        "                     for p in sub_path['point']])\n",
        "\n",
        "    # start with the first element, remove it from path\n",
        "    final = path[0]\n",
        "    path.pop(0)\n",
        "\n",
        "    # loop until the first and last coordinates in final match\n",
        "    counter = len(path)\n",
        "    done = True\n",
        "    while final[0] != final[-1]:\n",
        "        # loop through the sub-paths that we haven't yet moved to final\n",
        "        for i in range(len(path)):\n",
        "            # check if the last coordinate in final matches the first \n",
        "            # coordinate of another sub-path\n",
        "            if final[-1] == path[i][0]:\n",
        "                # match found, move it to final\n",
        "                # leave out the first coordinate to avoid duplicates\n",
        "                final = final + path[i][1:]\n",
        "                path.pop(i)\n",
        "                break  # break the for loop\n",
        "                \n",
        "        # protection against infinite loops, if the path never closes\n",
        "        counter -= 1\n",
        "        if counter < 0:\n",
        "            done = False\n",
        "            break\n",
        "\n",
        "    if not done:\n",
        "        # route did not connect in a loop, perform same steps backwards \n",
        "        # to get the rest of the line\n",
        "        for _ in range(len(path)):\n",
        "            # loop through the sub-paths that we haven't yet moved to final\n",
        "            for i in range(len(path)):\n",
        "                # check if the first coordinate in final matches the last \n",
        "                # coordinate of another sub-path\n",
        "                if final[0] == path[i][-1]:\n",
        "                    # match found, move it to final\n",
        "                    # leave out the last coordinate to avoid duplicates\n",
        "                    final = path[i][:-1] + final\n",
        "                    path.pop(i)\n",
        "                    break  # break the for loop\n",
        "\n",
        "    # some routes may have un-used sub-paths\n",
        "    # Route 1 for example has two sub-paths that are almost identical, with the \n",
        "    # same start and end points\n",
        "    # if len(path) > 0:\n",
        "    #     print(f\"WARNING: {len(path)} unused sub-paths\")\n",
        "\n",
        "    # return the final result\n",
        "    return final\n",
        "\n",
        "\n",
        "def extract_stops(route_data):\n",
        "  \"\"\"\n",
        "  Extracts a dataframe of stops info\n",
        "\n",
        "  Returns the main stops dataframe, and a list of inbound and outbound stops \n",
        "  in the order they are intended to be on the route\n",
        "  \"\"\"\n",
        "\n",
        "  stops = pd.DataFrame(route_data['stop'])\n",
        "  directions = pd.DataFrame(route_data['direction'])\n",
        "\n",
        "  # Change stop arrays to just the list of numbers\n",
        "  for i in range(len(directions)):\n",
        "    directions.at[i, 'stop'] = [s['tag'] for s in directions.at[i, 'stop']]\n",
        "\n",
        "  # Find which stops are inbound or outbound\n",
        "  inbound = []\n",
        "  for stop_list in directions[directions['name'] == \"Inbound\"]['stop']:\n",
        "    for stop in stop_list:\n",
        "      if stop not in inbound:\n",
        "        inbound.append(stop)\n",
        "\n",
        "  outbound = []\n",
        "  for stop_list in directions[directions['name'] == \"Outbound\"]['stop']:\n",
        "    for stop in stop_list:\n",
        "      if stop not in inbound:\n",
        "        outbound.append(stop)\n",
        "\n",
        "  # Label each stop as inbound or outbound\n",
        "  stops['direction'] = ['none'] * len(stops)\n",
        "  for i in range(len(stops)):\n",
        "    if stops.at[i, 'tag'] in inbound:\n",
        "      stops.at[i, 'direction'] = 'inbound'\n",
        "    elif stops.at[i, 'tag'] in outbound:\n",
        "      stops.at[i, 'direction'] = 'outbound'\n",
        "\n",
        "  # Convert from string to float\n",
        "  stops['lat'] = stops['lat'].astype(float)\n",
        "  stops['lon'] = stops['lon'].astype(float)\n",
        "\n",
        "  return stops, inbound, outbound"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfyIVYcuy6eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_location_data(rid, begin, end, connection):\n",
        "  # Build query to select location data\n",
        "  query = f\"\"\"\n",
        "    SELECT *\n",
        "    FROM locations\n",
        "    WHERE rid = '{rid}' AND\n",
        "      timestamp > '{begin}'::TIMESTAMP AND\n",
        "      timestamp < '{end}'::TIMESTAMP\n",
        "    ORDER BY id;\n",
        "  \"\"\"\n",
        "\n",
        "  # read the query directly into pandas\n",
        "  locations = sqlio.read_sql_query(query, connection)\n",
        "\n",
        "  # Convert those UTC timestamps to local PST by subtracting 7 hours\n",
        "  locations['timestamp'] = locations['timestamp'] - pd.Timedelta(hours=7)\n",
        "\n",
        "  # return the result\n",
        "  return locations\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi2_KkBuz8-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Written by Austie\n",
        "def fcc_projection(loc1, loc2):\n",
        "    \"\"\"\n",
        "    function to apply FCC recommended formulae\n",
        "    for calculating distances on earth projected to a plane\n",
        "    \n",
        "    significantly faster computationally, negligible loss in accuracy\n",
        "    \n",
        "    Args: \n",
        "    loc1 - a tuple of lat/lon\n",
        "    loc2 - a tuple of lat/lon\n",
        "    \"\"\"\n",
        "    lat1, lat2 = loc1[0], loc2[0]\n",
        "    lon1, lon2 = loc1[1], loc2[1]\n",
        "    \n",
        "    mean_lat = (lat1+lat2)/2\n",
        "    delta_lat = lat2 - lat1\n",
        "    delta_lon = lon2 - lon1\n",
        "    \n",
        "    k1 = 111.13209 - 0.56605*cos(2*mean_lat) + .0012*cos(4*mean_lat)\n",
        "    k2 = 111.41513*cos(mean_lat) - 0.09455*cos(3*mean_lat) + 0.00012*cos(5*mean_lat)\n",
        "    \n",
        "    distance = sqrt((k1*delta_lat)**2 + (k2*delta_lon)**2)\n",
        "    \n",
        "    return distance\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cehEnkae0nIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_locations(locations, stops):\n",
        "  \"\"\"\n",
        "  takes a dataframe of bus locations and a dataframe of \n",
        "\n",
        "  returns the locations dataframe with nearest stop added\n",
        "  \"\"\"\n",
        "  \n",
        "  # remove old location reports that would be duplicates\n",
        "  df = locations[locations['age'] < 60].copy()\n",
        "\n",
        "  # remove rows with no direction value\n",
        "  df = df[~pd.isna(df['direction'])]\n",
        "\n",
        "  # shift timestamps according to the age column\n",
        "  df['timestamp'] = df.apply(shift_timestamp, axis=1)\n",
        "\n",
        "  # Make lists of all inbound or outbound stops\n",
        "  inbound_stops = stops[stops['direction'] == 'inbound'].reset_index(drop=True)\n",
        "  outbound_stops = stops[stops['direction'] == 'outbound'].reset_index(drop=True)\n",
        "\n",
        "  # initialize new columns for efficiency\n",
        "  df['closestStop'] = [0] * len(df)\n",
        "  df['distance'] = [0.0] * len(df)\n",
        "\n",
        "  for i in df.index:\n",
        "    if '_I_' in df.at[i, 'direction']:\n",
        "      candidates = inbound_stops\n",
        "    elif '_O_' in df.at[i, 'direction']:\n",
        "      candidates = outbound_stops\n",
        "    else:\n",
        "      # Skip row if bus is not found to be either inbound or outbound\n",
        "      continue\n",
        "    \n",
        "    bus_coord = (df.at[i, 'latitude'], df.at[i, 'longitude'])\n",
        "\n",
        "    # Find closest stop within candidates\n",
        "    # Assume the first stop\n",
        "    closest = candidates.iloc[0]\n",
        "    distance = fcc_projection(bus_coord, (closest['lat'], closest['lon']))\n",
        "\n",
        "    # Check each stop after that\n",
        "    for _, row in candidates[1:].iterrows():\n",
        "      # find distance to this stop\n",
        "      dist = fcc_projection(bus_coord, (row['lat'], row['lon']))\n",
        "      if dist < distance:\n",
        "        # closer stop found, save it\n",
        "        closest = row\n",
        "        distance = dist\n",
        "    \n",
        "    # Save the tag of the closest stop and the distance to it\n",
        "    df.at[i, 'closestStop'] = closest['tag']\n",
        "    df.at[i, 'distance'] = distance\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def shift_timestamp(row):\n",
        "  \"\"\" subtracts row['age'] from row['timestamp'] \"\"\"\n",
        "  return row['timestamp'] - pd.Timedelta(seconds=row['age'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIIAo9Pe74TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stop_times(locations, route):\n",
        "  \"\"\"\n",
        "  returns a dict, keys are stop tags and values are lists of timestamps \n",
        "  that describe every time a bus was seen at that stop\n",
        "  \"\"\"\n",
        "  start = time()\n",
        "  # Initialize the data structure I will store results in\n",
        "  stop_times = {}\n",
        "  vids = {}\n",
        "  for stop in route.inbound + route.outbound:\n",
        "    stop_times[str(stop)] = []\n",
        "\n",
        "  for vid in locations['vid'].unique():\n",
        "    # Process the route one vehicle at a time\n",
        "    df = locations[locations['vid'] == vid]\n",
        "\n",
        "    # process 1st row on its own\n",
        "    prev_row = df.loc[df.index[0]]\n",
        "    stop_times[str(prev_row['closestStop'])].append(prev_row['timestamp'])\n",
        "\n",
        "    # loop through the rest of the rows, comparing each to the previous one\n",
        "    for i, row in df[1:].iterrows():\n",
        "      if row['direction'] != prev_row['direction']:\n",
        "        # changed directions, don't compare to previous row\n",
        "        stop_times[str(row['closestStop'])].append(row['timestamp'])\n",
        "      else:\n",
        "        # same direction, compare to previous row\n",
        "        if '_I_' in row['direction']:  # get correct stop list\n",
        "          stoplist = route.inbound\n",
        "        else:\n",
        "          stoplist = route.outbound\n",
        "\n",
        "        current = stoplist.index(str(row['closestStop']))\n",
        "        previous = stoplist.index(str(prev_row['closestStop']))\n",
        "        gap = current - previous\n",
        "        if gap > 1:  # need to interpolate\n",
        "          diff = (row['timestamp'] - prev_row['timestamp'])/gap\n",
        "          counter = 1\n",
        "          for stop in stoplist[previous+1:current]:\n",
        "            # save interpolated time\n",
        "            stop_times[str(stop)].append(prev_row['timestamp'] + (counter * diff))\n",
        "\n",
        "            # increase counter for the next stop\n",
        "            # example: with 2 interpolated stops, gap would be 3\n",
        "            # 1st diff is 1/3, next is 2/3\n",
        "            counter += 1\n",
        "        \n",
        "        if row['closestStop'] != prev_row['closestStop']:\n",
        "          # only save time if the stop has changed, \n",
        "          # otherwise the bus hasn't moved since last time\n",
        "          stop_times[str(row['closestStop'])].append(row['timestamp'])\n",
        "      \n",
        "      # advance for next row\n",
        "      prev_row = row\n",
        "\n",
        "  # Sort each list before returning\n",
        "  for stop in stop_times.keys():\n",
        "    stop_times[stop].sort()\n",
        "\n",
        "  return stop_times\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh5YpJtYBNP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bunches_gaps(stop_times, schedule, bunch_threshold=.2, gap_threshold=1.5):\n",
        "  \"\"\"\n",
        "  returns a dataframe of all bunches and gaps found\n",
        "\n",
        "  default thresholds define a bunch as 20% and a gap as 150% of scheduled headway\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize dataframe for the bunces and gaps\n",
        "  problems = pd.DataFrame(columns=['type', 'time', 'duration', 'stop'])\n",
        "  counter = 0\n",
        "\n",
        "  # Set the bunch/gap thresholds (in seconds)\n",
        "  bunch_threshold = (schedule.common_interval * 60) * bunch_threshold\n",
        "  gap_threshold = (schedule.common_interval * 60) * gap_threshold\n",
        "\n",
        "  for stop in stop_times.keys():\n",
        "    # ensure we have any times at all for this stop\n",
        "    if len(stop_times[stop]) == 0:\n",
        "      #print(f\"Stop {stop} had no recorded times\")\n",
        "      continue  # go to next stop in the loop\n",
        "\n",
        "    # save initial time\n",
        "    prev_time = stop_times[stop][0]\n",
        "\n",
        "    # loop through all others, comparing to the previous one\n",
        "    for time in stop_times[stop][1:]:\n",
        "      diff = (time - prev_time).seconds\n",
        "      if diff <= bunch_threshold:\n",
        "        # bunch found, save it\n",
        "        problems.at[counter] = ['bunch', prev_time, diff, stop]\n",
        "        counter += 1\n",
        "      elif diff >= gap_threshold:\n",
        "        problems.at[counter] = ['gap', prev_time, diff, stop]\n",
        "        counter += 1\n",
        "      \n",
        "      prev_time = time\n",
        "  \n",
        "  return problems\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaOhrtrBD09m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this uses sequential search, could speed up with binary search if needed,\n",
        "# but it currently uses hardly any time in comparison to other steps\n",
        "def helper_count(expected_times, observed_times):\n",
        "  \"\"\" Returns the number of on-time stops found \"\"\"\n",
        "\n",
        "  # set up early/late thresholds (in seconds)\n",
        "  early_threshold = pd.Timedelta(seconds=1*60)  # 1 minute early\n",
        "  late_threshold = pd.Timedelta(seconds=4*60)   # 4 minutes late\n",
        "\n",
        "  count = 0\n",
        "  for stop in expected_times.columns:\n",
        "    for expected in expected_times[stop]:\n",
        "      if pd.isna(expected):\n",
        "        continue  # skip NaN values in the expected schedule\n",
        "\n",
        "      # for each expected time...\n",
        "      # find first observed time after the early threshold\n",
        "      found_time = None\n",
        "      early = expected - early_threshold\n",
        "\n",
        "      # BUG: some schedule data may have stop tags that are not in the inbound\n",
        "      # or outbound definitions for a route.  That would throw a key error here.\n",
        "      # Example: stop 14148 on route 24\n",
        "      # current solution is to ignore those stops with the try/except statement\n",
        "      try:\n",
        "        for observed in observed_times[stop]:\n",
        "          if observed >= early:\n",
        "            found_time = observed\n",
        "            break\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      # if found time is still None, then all observed times were too early\n",
        "      # if found_time is before the late threshold then we were on time\n",
        "      if (not pd.isna(found_time)) and found_time <= (expected + late_threshold):\n",
        "        # found_time is within the on-time window\n",
        "        count += 1\n",
        "\n",
        "  return count\n",
        "\n",
        "def calculate_ontime(stop_times, schedule):\n",
        "  \"\"\" Returns the on-time percentage and total scheduled stops for this route \"\"\"\n",
        "\n",
        "  # Save schedules with timestamp data types, set date to match\n",
        "  inbound_times = schedule.inbound_table\n",
        "  for col in inbound_times.columns:\n",
        "    inbound_times[col] = pd.to_datetime(inbound_times[col]).apply(\n",
        "        lambda dt: dt.replace(year=schedule.date.year, \n",
        "                              month=schedule.date.month, \n",
        "                              day=schedule.date.day))\n",
        "\n",
        "  outbound_times = schedule.outbound_table\n",
        "  for col in outbound_times.columns:\n",
        "    outbound_times[col] = pd.to_datetime(outbound_times[col]).apply(\n",
        "        lambda dt: dt.replace(year=schedule.date.year, \n",
        "                              month=schedule.date.month, \n",
        "                              day=schedule.date.day))\n",
        "  \n",
        "  # count times for both inbound and outbound schedules\n",
        "  on_time_count = (helper_count(inbound_times, stop_times) +\n",
        "                   helper_count(outbound_times, stop_times))\n",
        "  \n",
        "  # get total expected count\n",
        "  total_expected = inbound_times.count().sum() + outbound_times.count().sum()\n",
        "\n",
        "  # return on-time percentage\n",
        "  return (on_time_count / total_expected), total_expected\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOyWGDKPSF8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bunch_gap_graph(problems, interval=10):\n",
        "  \"\"\"\n",
        "  returns data for a graph of the bunches and gaps throughout the day\n",
        "\n",
        "  problems - the dataframe of bunches and gaps\n",
        "\n",
        "  interval - the number of minutes to bin data into\n",
        "\n",
        "  returns\n",
        "  {\n",
        "    \"times\": [time values (x)],\n",
        "    \"bunches\": [bunch counts (y1)],\n",
        "    \"gaps\": [gap counts (y2)]\n",
        "  }\n",
        "  \"\"\"\n",
        "\n",
        "  # set the time interval\n",
        "  interval = pd.Timedelta(minutes=interval)\n",
        "\n",
        "  # rest of code doesn't work if there are no bunches or gaps\n",
        "  # return the empty graph manually\n",
        "  if len(problems) == 0:\n",
        "    # generate list of times according to the interval\n",
        "    start = pd.Timestamp('today').replace(hour=0, minute=0, second=0)\n",
        "    t = start\n",
        "    times = []\n",
        "    while t.day == start.day:\n",
        "      times.append(str(t.time())[:5])\n",
        "      t += interval\n",
        "\n",
        "    return {\n",
        "      \"times\": times,\n",
        "      \"bunches\": [0] * len(times),\n",
        "      \"gaps\": [0] * len(times)\n",
        "    }\n",
        "\n",
        "  # generate the DatetimeIndex needed\n",
        "  index = pd.DatetimeIndex(problems['time'])\n",
        "  df = problems.copy()\n",
        "  df.index = index\n",
        "\n",
        "  # lists for graph data\n",
        "  bunches = []\n",
        "  gaps = []\n",
        "  times = []\n",
        "  \n",
        "  # set selection times\n",
        "  start_date = problems.at[0, 'time'].replace(hour=0, minute=0, second=0)\n",
        "  select_start = start_date\n",
        "  select_end = select_start + interval\n",
        "\n",
        "  while select_start.day == start_date.day:\n",
        "    # get the count of each type of problem in this time interval\n",
        "    count = df.between_time(select_start.time(), select_end.time())['type'].value_counts()\n",
        "\n",
        "    # append the counts to the data list\n",
        "    if 'bunch' in count.index:\n",
        "      bunches.append(int(count['bunch']))\n",
        "    else:\n",
        "      bunches.append(0)\n",
        "    \n",
        "    if 'gap' in count.index:\n",
        "      gaps.append(int(count['gap']))\n",
        "    else:\n",
        "      gaps.append(0)\n",
        "\n",
        "    # save the start time for the x axis\n",
        "    times.append(str(select_start.time())[:5])\n",
        "    \n",
        "    # increment the selection window\n",
        "    select_start += interval\n",
        "    select_end += interval\n",
        "  \n",
        "  return {\n",
        "    \"times\": times,\n",
        "    \"bunches\": bunches,\n",
        "    \"gaps\": gaps\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA6EKTBOvi9a",
        "colab_type": "text"
      },
      "source": [
        "## Necessary for geojson"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR0NHq3n2CI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_simple_geojson(bunches, rid):\n",
        "\n",
        "    geojson = {'type': 'FeatureCollection',\n",
        "               'bunches': create_geojson_features(bunches, rid)}\n",
        "\n",
        "    return geojson"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgpWAy5v54Sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_geojson_features(df, rid):\n",
        "    \"\"\"\n",
        "    function to generate list of geojson features\n",
        "    for plotting vehicle locations on timestamped map\n",
        "\n",
        "    Expects a dataframe containing lat/lon, vid, timestamp\n",
        "    returns list of basic geojson formatted features:\n",
        "\n",
        "    {\n",
        "      type: Feature\n",
        "      geometry: {\n",
        "        type: Point,\n",
        "        coordinates:[lat, lon]\n",
        "      },\n",
        "      properties: {\n",
        "        route_id: rid\n",
        "        time: timestamp\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "    # initializing empty features list\n",
        "    features = []\n",
        "\n",
        "    # iterating through df to pull coords, vid, timestamp\n",
        "    # and format for json\n",
        "    for index, row in df.iterrows():\n",
        "      feature = {\n",
        "          'type': 'Feature',\n",
        "          'geometry': {\n",
        "              'type':'Point', \n",
        "              'coordinates':[row.lon, row.lat]\n",
        "          },\n",
        "          'properties': {\n",
        "              'time': row.time.__str__(),\n",
        "              'stop': {'stopId': row.stopId.__str__(),\n",
        "                       'stopTitle': row.title.__str__()},\n",
        "              'direction': row.direction.__str__()\n",
        "          }\n",
        "      }\n",
        "      features.append(feature) # adding point to features list\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuDqm1avLb8r",
        "colab_type": "text"
      },
      "source": [
        "## Generating report JSON\n",
        "\n",
        "Now updated to include geojson for mapping.\n",
        "\n",
        "Tested geojson generation with: \n",
        "- single report generation \n",
        "- all routes generation\n",
        "- aggregate generation\n",
        "\n",
        "Tested mapping bunches with generated geojson W/ Folium. \n",
        "\n",
        "Everything should plug-and-play."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T35JXa91LfFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_report(rid, date):\n",
        "  \"\"\"\n",
        "  Generates a daily report for the given rid and date\n",
        "\n",
        "  rid : (str)\n",
        "    the route id to generate a report for\n",
        "  \n",
        "  date : (str or pd.Datetime)\n",
        "    the date to generate a report for\n",
        "\n",
        "  returns a dict of the report info\n",
        "  \"\"\"\n",
        "\n",
        "  # get begin and end timestamps for the date\n",
        "  begin = pd.to_datetime(date).replace(hour=7)\n",
        "  end = begin + pd.Timedelta(days=1)\n",
        "  # Load schedule and route data\n",
        "  schedule = Schedule(rid, begin, cnx)\n",
        "  \n",
        "  route = Route(rid, begin, cnx)\n",
        "  \n",
        "  # Load bus location data\n",
        "  locations = get_location_data(rid, begin, end, cnx)\n",
        "  \n",
        "  # Apply cleaning function (this usually takes 1-2 minutes)\n",
        "  locations = clean_locations(locations, route.stops_table)\n",
        "  \n",
        "  # Calculate all times a bus was at each stop\n",
        "  stop_times = get_stop_times(locations, route)\n",
        "\n",
        "  # Find all bunches and gaps\n",
        "  problems = get_bunches_gaps(stop_times, schedule)\n",
        "\n",
        "  # Calculate on-time percentage\n",
        "  on_time, total_scheduled = calculate_ontime(stop_times, schedule)\n",
        "\n",
        "  # Build result dict\n",
        "  count_times = 0\n",
        "  for key in stop_times.keys():\n",
        "    count_times += len(stop_times[key])\n",
        "\n",
        "  # Number of recorded intervals ( sum(len(each list of time)) - number or lists of times)\n",
        "  intervals = count_times-len(stop_times)\n",
        "\n",
        "  bunches = len(problems[problems['type'] == 'bunch'])\n",
        "  gaps = len(problems[problems['type'] == 'gap'])\n",
        "\n",
        "  coverage = (total_scheduled * on_time + bunches) / total_scheduled\n",
        "  \n",
        "  # Isolating bunches, merging with stops to assign locations to bunches\n",
        "  stops = route.stops_table.copy()\n",
        "\n",
        "  bunch_df = problems[problems.type.eq('bunch')]\n",
        "  bunch_df = bunch_df.merge(stops, left_on='stop', right_on='tag', how='left')\n",
        "\n",
        "  # Creating GeoJSON of bunch times / locations\n",
        "  geojson = create_simple_geojson(bunch_df, rid)\n",
        "  \n",
        "  # int/float conversions are because the json library doesn't work with numpy types\n",
        "  result = {\n",
        "      'route': rid,\n",
        "      'route_name': route.route_name,\n",
        "      'route_type': route.route_type,\n",
        "      'date': str(pd.to_datetime(date)),\n",
        "      'num_bunches': bunches,\n",
        "      'num_gaps': gaps,\n",
        "      'total_intervals': intervals,\n",
        "      'on_time_percentage': float(round(on_time * 100, 2)),\n",
        "      'scheduled_stops': int(total_scheduled),\n",
        "      'coverage': float(round(coverage * 100, 2)),\n",
        "      # line_chart contains all data needed to generate the line chart\n",
        "      'line_chart': bunch_gap_graph(problems, interval=10),\n",
        "      # route_table is an array of all rows that should show up in the table\n",
        "      # it will be filled in after all reports are generated\n",
        "      'route_table': [\n",
        "          {\n",
        "            'route_name': route.route_name,\n",
        "            'bunches': bunches,\n",
        "            'gaps': gaps,\n",
        "            'on-time': float(round(on_time * 100, 2)),\n",
        "            'coverage': float(round(coverage * 100, 2))\n",
        "          }\n",
        "      ],\n",
        "      'geojson': geojson\n",
        "  }\n",
        "\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDuD8zIiM1IL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "11c46dfb-4637-4fd3-c065-423f19e10f85"
      },
      "source": [
        "%%time\n",
        "\n",
        "report_1 = generate_report(rid='1', date='2020/6/1')"
      ],
      "execution_count": 565,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 12s, sys: 38.7 ms, total: 1min 12s\n",
            "Wall time: 1min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F0hL92BYZrw",
        "colab_type": "code",
        "outputId": "22f43ef3-b370-4a87-ac02-bfb16fa31f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "report_1['geojson']['bunches'][:5]"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'geometry': {'coordinates': [-122.49311, 37.7797399], 'type': 'Point'},\n",
              "  'properties': {'direction': 'inbound',\n",
              "   'stop': {'stopId': '14277', 'stopTitle': 'Geary Blvd & 33rd Ave'},\n",
              "   'time': '2020-06-01 13:44:03'},\n",
              "  'type': 'Feature'},\n",
              " {'geometry': {'coordinates': [-122.49311, 37.7797399], 'type': 'Point'},\n",
              "  'properties': {'direction': 'inbound',\n",
              "   'stop': {'stopId': '14277', 'stopTitle': 'Geary Blvd & 33rd Ave'},\n",
              "   'time': '2020-06-01 14:34:38'},\n",
              "  'type': 'Feature'},\n",
              " {'geometry': {'coordinates': [-122.49311, 37.7797399], 'type': 'Point'},\n",
              "  'properties': {'direction': 'inbound',\n",
              "   'stop': {'stopId': '14277', 'stopTitle': 'Geary Blvd & 33rd Ave'},\n",
              "   'time': '2020-06-01 21:49:39'},\n",
              "  'type': 'Feature'},\n",
              " {'geometry': {'coordinates': [-122.49335, 37.78154], 'type': 'Point'},\n",
              "  'properties': {'direction': 'inbound',\n",
              "   'stop': {'stopId': '13555', 'stopTitle': '33rd Ave & Clement St'},\n",
              "   'time': '2020-06-01 13:58:05'},\n",
              "  'type': 'Feature'},\n",
              " {'geometry': {'coordinates': [-122.49335, 37.78154], 'type': 'Point'},\n",
              "  'properties': {'direction': 'inbound',\n",
              "   'stop': {'stopId': '13555', 'stopTitle': '33rd Ave & Clement St'},\n",
              "   'time': '2020-06-01 14:05:01'},\n",
              "  'type': 'Feature'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 464
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqXvyN0UYeHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_714 = generate_report(rid='714', date='2020/6/1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoOyHgnEY3oP",
        "colab_type": "code",
        "outputId": "e7800a1a-1f9c-4360-c68a-74f37d2b2e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "report_714['geojson']['bunches']"
      ],
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 471
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I51BkjZQcMAW",
        "colab_type": "text"
      },
      "source": [
        "# Generating report for all routes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHvTg7PecoBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_active_routes(date):\n",
        "  \"\"\"\n",
        "  returns a list of all active route id's for the given date\n",
        "  \"\"\"\n",
        "\n",
        "  query = \"\"\"\n",
        "    SELECT DISTINCT rid\n",
        "    FROM routes\n",
        "    WHERE begin_date <= %s ::TIMESTAMP AND\n",
        "          (end_date IS NULL OR end_date > %s ::TIMESTAMP);\n",
        "  \"\"\"\n",
        "\n",
        "  cursor.execute(query, (date, date))\n",
        "  return [result[0] for result in cursor.fetchall()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW_0FZS9cLWS",
        "colab_type": "code",
        "outputId": "695520d2-1ee1-462e-ce38-11b5b968e6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "%%time\n",
        "# since this is not optimized yet, this takes about 20 minutes\n",
        "\n",
        "# choose a day\n",
        "date = '2020-6-1'\n",
        "\n",
        "# get all active routes \n",
        "route_ids = get_active_routes(date)\n",
        "\n",
        "# get the report for all routes\n",
        "all_reports = []\n",
        "for rid in route_ids:\n",
        "  try:\n",
        "    all_reports.append(generate_report(rid, date))\n",
        "    print(\"Generated report for route\", rid)\n",
        "  except: # in case any particular route throws an error\n",
        "    print(f\"Route {rid} failed\")"
      ],
      "execution_count": 558,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated report for route 1\n",
            "Generated report for route NBUS\n",
            "CPU times: user 2min 40s, sys: 97.7 ms, total: 2min 41s\n",
            "Wall time: 2min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeoOjE4HlDAh",
        "colab_type": "code",
        "outputId": "77957ab1-839e-458a-e38a-1abc6086626e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(all_reports)"
      ],
      "execution_count": 559,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 559
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e69gtrmh0cBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate aggregate reports\n",
        "\n",
        "# read existing reports into a dataframe to work with them easily\n",
        "df = pd.DataFrame(all_reports)\n",
        "\n",
        "# for each aggregate type\n",
        "types = list(df['route_type'].unique()) + ['All']\n",
        "for t in types:\n",
        "  # filter df to the routes we are adding up\n",
        "  if t == 'All':\n",
        "    filtered = df\n",
        "  else:\n",
        "    filtered = df[df['route_type'] == t]\n",
        "\n",
        "  # on-time percentage: sum([all on-time stops]) / sum([all scheduled stops])\n",
        "  count_on_time = (filtered['on_time_percentage'] * filtered['scheduled_stops']).sum()\n",
        "  on_time_perc = count_on_time / filtered['scheduled_stops'].sum()\n",
        "\n",
        "  # coverage: (sum([all on-time stops]) + sum([all bunches])) / sum([all scheduled stops])\n",
        "  coverage = (count_on_time + filtered['num_bunches'].sum()) / filtered['scheduled_stops'].sum()\n",
        "\n",
        "  # aggregate the graph object\n",
        "  # x-axis is same for all\n",
        "  first = filtered.index[0]\n",
        "  times = filtered.at[first, 'line_chart']['times']\n",
        "\n",
        "  # sum up all y-axis values\n",
        "  bunches = pd.Series(filtered.at[first, 'line_chart']['bunches'])\n",
        "  gaps = pd.Series(filtered.at[first, 'line_chart']['gaps'])\n",
        "\n",
        "  for chart in filtered[1:]['line_chart']:\n",
        "    bunches += pd.Series(chart['bunches'])\n",
        "    gaps += pd.Series(chart['gaps'])\n",
        "\n",
        "  # save a new report object\n",
        "  new_report = {\n",
        "      'route': t,\n",
        "      'route_name': t,\n",
        "      'route_type': t,\n",
        "      'date': all_reports[0]['date'],\n",
        "      'num_bunches': int(filtered['num_bunches'].sum()),\n",
        "      'num_gaps': int(filtered['num_gaps'].sum()),\n",
        "      'total_intervals': int(filtered['total_intervals'].sum()),\n",
        "      'on_time_percentage': float(round(on_time_perc, 2)),\n",
        "      'scheduled_stops': int(filtered['scheduled_stops'].sum()),\n",
        "      'coverage': float(round(coverage, 2)),\n",
        "      'line_chart': {\n",
        "          'times': times,\n",
        "          'bunches': list(bunches),\n",
        "          'gaps': list(bunches)\n",
        "      },\n",
        "      'route_table': [\n",
        "          {\n",
        "            'route_name': t,\n",
        "            'bunches': int(filtered['num_bunches'].sum()),\n",
        "            'gaps': int(filtered['num_gaps'].sum()),\n",
        "            'on-time': float(round(on_time_perc, 2)),\n",
        "            'coverage': float(round(coverage, 2))\n",
        "          }\n",
        "      ]\n",
        "  }\n",
        "\n",
        "  # TODO: add route_table rows to the aggregate report\n",
        "\n",
        "  all_reports.append(new_report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sFAns_VF7MG",
        "colab_type": "code",
        "outputId": "09007cd0-568a-4ae5-f2a5-7b23c2e275b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "all_reports[0].keys()"
      ],
      "execution_count": 564,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['route', 'route_name', 'route_type', 'date', 'num_bunches', 'num_gaps', 'total_intervals', 'on_time_percentage', 'scheduled_stops', 'coverage', 'line_chart', 'route_table', 'geojson'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 564
        }
      ]
    }
  ]
}