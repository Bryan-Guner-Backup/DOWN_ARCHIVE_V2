{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "import shutil\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import re \n",
    "import speech_recognition as sr\n",
    "import os\n",
    "import moviepy.editor\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import keras\n",
    "import wave\n",
    "import contextlib\n",
    "from keras.models import Model, model_from_json\n",
    "import tensorflow as tf\n",
    "import glob \n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the ML model, weights, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load models\n",
    "# loading json and model architecture \n",
    "json_file = open('MLModel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"Augmented_Model.h5\")\n",
    " \n",
    "# compile loaded model\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# load lables\n",
    "infile = open('labels','rb')\n",
    "lb = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Audio Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_from_video():\n",
    "    video = moviepy.editor.VideoFileClip('lecture_clip.mp4')\n",
    "    audio = video.audio\n",
    "    audio.write_audiofile('audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_analysis():\n",
    "    #get_audio_from_video()\n",
    "    audio = AudioSegment.from_file(\"audio.wav\", \"wav\")\n",
    "    chunk_length_ms = 4000\n",
    "    chunks = make_chunks(audio, chunk_length_ms)\n",
    "    \n",
    "    #Export all of the individual chunks as wav files\n",
    "    path = \"audio_sentiment/\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "        \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_name = \"audio_sentiment/chunk{0}.wav\".format(i)\n",
    "        chunk.export(chunk_name, format=\"wav\")\n",
    "    \n",
    "    lists_of_files = os.listdir(path)\n",
    "    test_predictions = pd.DataFrame(columns=['predictions'])\n",
    "    \n",
    "    for filename in lists_of_files:\n",
    "        try:\n",
    "            data, sample_rate = librosa.load(\"audio_sentiment/{}\".format(filename),\n",
    "                                             res_type='kaiser_fast',\n",
    "                                             sr=44100)\n",
    "            #print(filename)\n",
    "            sample_rate = np.array(sample_rate)\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "            newdf = pd.DataFrame(data=mfccs).T\n",
    "            \n",
    "            # Apply predictions\n",
    "            newdf= np.expand_dims(newdf, axis=2)\n",
    "            newpred = loaded_model.predict(newdf,batch_size=16,verbose=1)\n",
    "            \n",
    "            # Get the final predicted label\n",
    "            final = newpred.argmax(axis=1)\n",
    "            final = final.astype(int).flatten()\n",
    "            final = (lb.inverse_transform((final)))\n",
    "            #print(final)\n",
    "            test_predictions.loc[filename] = final\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    labels = test_predictions.predictions.value_counts(normalize=True).keys().tolist()\n",
    "    \n",
    "    values= []\n",
    "    predictions = {} \n",
    "    for i in test_predictions.predictions.value_counts(normalize=True).tolist():\n",
    "        values.append(round(i,2))   \n",
    "    for key in labels:\n",
    "        for value in values:\n",
    "            predictions[key] = value\n",
    "            values.remove(value) \n",
    "            break\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Speed of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_audio_file(file_name = 'audio.wav'):\n",
    "    \"\"\"\n",
    "    Breaks an audio file into smaller chunks\n",
    "    \"\"\"\n",
    "    myaudio = AudioSegment.from_file(file_name, \"wav\") \n",
    "    chunk_length_ms = 30000 # pydub calculates in millisec\n",
    "    chunks = make_chunks(myaudio, chunk_length_ms) #Make chunks of 30 sec\n",
    "\n",
    "    #Export all of the individual chunks as wav files\n",
    "    path = \"audio_chunks/\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_name = \"audio_chunks/chunk{0}.wav\".format(i)\n",
    "        chunk.export(chunk_name, format=\"wav\")\n",
    "        \n",
    "dirname = \"audio_chunks/\"\n",
    "def get_file_paths(dirname):\n",
    "    \"\"\"\n",
    "    Gets file paths from the directory\n",
    "    \"\"\"\n",
    "    file_paths = []  \n",
    "    for root, directories, files in os.walk(dirname):\n",
    "        for filename in files:\n",
    "            filepath = os.path.join(root, filename)\n",
    "            file_paths.append(filepath)  \n",
    "    return file_paths \n",
    "\n",
    "def process_file(file):\n",
    "    \"\"\"\n",
    "    Applies SpeechRecognition to the audio files\n",
    "    \"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    a = ''\n",
    "    with sr.AudioFile(file) as source:\n",
    "        #r.adjust_for_ambient_noise(source)  # adjust for noisy audio\n",
    "        audio = r.record(source)    \n",
    "        try:\n",
    "            a =  r.recognize_google(audio)   # recognize_google_cloud\n",
    "        except sr.UnknownValueError:\n",
    "            a = \"Google Speech Recognition could not understand audio\"\n",
    "        except sr.RequestError as e:\n",
    "            a = \"Could not request results from Google Speech Recognition service; {0}\".format(e)  \n",
    "    return a\n",
    "\n",
    "\n",
    "def get_text():\n",
    "    # Create a new directory to store the chunks of txt\n",
    "    path = 'text_chunks/'\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "    \n",
    "    files = get_file_paths(dirname)                             \n",
    "    for file in files:                                           \n",
    "        (filepath, ext) = os.path.splitext(file)                  \n",
    "        file_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        # only interested if extension is '.wav'\n",
    "        if ext == '.wav':                                         \n",
    "            a = process_file(file)\n",
    "            with open(\"text_chunks/{}.txt\".format(file_name), \"w\") as f:\n",
    "                f.write(a+\". \")                            \n",
    "\n",
    "path = r\"text_chunks/\"\n",
    "def get_transcripts_from_audio(audio_file='audio.wav'):\n",
    "    \"\"\"\n",
    "    A function to get a transcripts from the audio (stores text into separate chunks of text)\n",
    "    \"\"\"\n",
    "    break_audio_file()\n",
    "    get_text()\n",
    "    files = get_file_paths(path)\n",
    "    files.sort(key=lambda x: int(re.sub('\\D', '', x)))\n",
    "    #sorted(files, key=lambda x: int(re.sub('\\D', '', x)))\n",
    "    with open('outputfile.txt', 'w+') as f: \n",
    "        for file in files:\n",
    "            with open(file) as infile:\n",
    "                f.write(infile.read()+'\\n')\n",
    "    \n",
    "#path = r\"text_chunks/\"\n",
    "#def get_combined_text(path):\n",
    "#    \"\"\"\n",
    "#    Combines all of the separate chunks of text into one file\n",
    "#    \"\"\"\n",
    "#    files = get_file_paths(path)\n",
    "#    files.sort(key=lambda x: int(re.sub('\\D', '', x)))\n",
    "#    #sorted(files, key=lambda x: int(re.sub('\\D', '', x)))\n",
    "#    with open('outputfile.txt', 'w+') as f: \n",
    "#        for file in files:\n",
    "#            with open(file) as infile:\n",
    "#                f.write(infile.read()+'\\n')\n",
    "                \n",
    "# Tokenize data\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text)]   # (if token not in STOPWORDS)\n",
    "\n",
    "def gather_data(path_to_data): \n",
    "    data = []\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isdir(f) == False:\n",
    "            if f[-3:] == 'txt':\n",
    "                with open(os.path.join(path,f)) as t:\n",
    "                    text = t.read().strip('\\n')\n",
    "                    data.append(tokenize(str(text)))       \n",
    "    return data\n",
    "\n",
    "def get_audio_duration(file_name = 'audio.wav'):\n",
    "    with contextlib.closing(wave.open(file_name,'r')) as f:\n",
    "        frames = f.getnframes()\n",
    "        rate = f.getframerate()\n",
    "        duration = (frames / float(rate)) / 60\n",
    "        return duration\n",
    "    \n",
    "def get_speed_of_speech():\n",
    "    tokens = gather_data('outputfile.txt')\n",
    "    \n",
    "    count = 0\n",
    "    for i in tokens:\n",
    "        count += len(i)\n",
    "        \n",
    "    speed_of_speech = count / get_audio_duration(file_name = 'audio.wav')\n",
    "    return speed_of_speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Text (from Audio) Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_sentiment(file = 'outputfile.txt'):\n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read()\n",
    "        sentiment = TextBlob(text).sentiment.polarity\n",
    "        return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to remove directories and files after we are done with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_files():\n",
    "    \"\"\"\n",
    "    Removes files and directories after they're no longer needed\n",
    "    \"\"\"\n",
    "    paths = ['audio_chunks/', 'audio_sentiment/', 'text_chunks/']\n",
    "    os.remove('outputfile.txt')\n",
    "    \n",
    "    for i in paths:\n",
    "        try:\n",
    "            shutil.rmtree(i)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s : %s\" % (i, e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main function to analyse the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_audio():\n",
    "    path = r\"text_chunks/\"\n",
    "    audio_sentiment = get_sentiment_analysis()\n",
    "    get_transcripts_from_audio(audio_file='audio.wav')\n",
    "    #get_combined_text(path)\n",
    "    speed_of_speech = get_speed_of_speech()\n",
    "    text_sentiment = get_text_sentiment()\n",
    "    return audio_sentiment, text_sentiment, speed_of_speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   2%|▏         | 106/4562 [00:00<00:04, 1059.33it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "get_audio_from_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory audio_sentiment/ \n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Successfully created the directory audio_chunks/ \n",
      "Successfully created the directory text_chunks/ \n"
     ]
    }
   ],
   "source": [
    "data = analyse_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'positive': 0.41, 'neutral': 0.31, 'negative': 0.27},\n",
       " 0.20464141414141415,\n",
       " 130.51674964953835)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment:\n",
    "# Polarity is float which lies in the range of [-1,1] \n",
    "# where 1 means positive statement and -1 means a negative statement. \n",
    "# Subjective sentences generally refer to personal opinion, \n",
    "# emotion or judgment whereas objective refers to factual information. \n",
    "# Subjectivity is also a float which lies in the range of [0,1].\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['positive'] + data[0]['neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"positive\": 0.41, \"neutral\": 0.31, \"negative\": 0.27}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_filename = 'outputfile.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so I want to set some expectations for the Sprint challenge challenge is I'm going to be honest is a little bit easier than normal because he's models are way harder to run then you have time to feasibly run a Sprint challenge so what can you expect tomorrow number one expecting lstm text classification problems you should definitely expect that number to I do expect you guys to be able to do some transfer learning so I'll be giving you a model.  you going to do some transfer learning about model music careless applications thing though you're not going to Central Hub so be kind of stuff you were familiar with from Tuesday's lecture and she stays assignment autoencoders you early have time to train two models not 3 so just expect some questions about autoencoders and then on some questions.  existential questions challenge tomorrow you guys best study guide should have you very well prepared for tomorrow have some fun I will be doing office hours this afternoon and you guys are welcome to come and we can continue this conversation and talk the other fun models out there I also want to last name glass thoughts less to thoughts Before I Let You Go there's so much more to explore.  world of neural networks and we have just touch the tip the iceberg like literally went on the research of neural networks so as you begin to think about what you're interested in is seriously like recent tutorials go on sensor flows website and go through all the trials that you're interested in collab has tons of tutorials.  when you're ready to move on to something if you're really interested in your own that works want to continue the next resource I highly recommend is the fast. AI course students go to that all the time once they're done with this unit it's really good the class is done in pytorch so it's not tensorflow but it'll go into a lot of the same.  free or do it on paper space or something like that and do it all for free then if you want to like if you're really really interested and want to continue taking the stuff on to the next level the book the books I recommend is keep learning in cheras I think I left it upstairs but it's 5 now.  Shakib Khan do that book is awesome I'm hoping that he releases the new version this year cuz I think it was published in 2017 and then beyond that if you really want to go into some of the math I recommend Ian Goodfellow deep learning book and that's really high-level really mathematical but it's worth giving a read at least some select chapters.  \n"
     ]
    }
   ],
   "source": [
    "transcript_string = open(transcript_filename).read().replace(\"\\n\", \" \")\n",
    "print(transcript_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(transcript_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3-6",
   "language": "python",
   "name": "python-3-6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}